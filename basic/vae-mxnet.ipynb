{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Variational Autoencoder in MXNet/Gluon\n",
    "\n",
    "This is the implementation using the classic MXNet API, i.e. mxnet.sym, mxnet.mod etc.\n",
    "\n",
    "Ref paper: Kingma, Diederik P., and Max Welling. [\"Auto-encoding variational bayes.\"](https://arxiv.org/abs/1312.6114) arXiv preprint arXiv:1312.6114 (2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from mxnet import nd, autograd, gluon\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "data_ctx = mx.cpu()\n",
    "model_ctx = mx.cpu(0)\n",
    "mx.random.seed(1)\n",
    "output_fig = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mx.test_utils.get_mnist()\n",
    "#print(mnist['train_data'][0].shape)\n",
    "#plt.imshow(mnist['train_data'][0][0],cmap='Greys')\n",
    "\n",
    "n_samples = 10\n",
    "idx = np.random.choice(len(mnist['train_data']), n_samples)\n",
    "_, axarr = plt.subplots(1, n_samples, figsize=(16,4))\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[i].imshow(mnist['train_data'][j][0], cmap='Greys')\n",
    "    #axarr[i].axis('off')\n",
    "    axarr[i].get_xaxis().set_ticks([])\n",
    "    axarr[i].get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.reshape(mnist['train_data'],(-1,28*28))\n",
    "test_data = np.reshape(mnist['test_data'],(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['test_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = train_data.shape[0]/batch_size\n",
    "train_iter = mx.io.NDArrayIter(data={'data': train_data}, label={'label': train_data}, batch_size = batch_size)\n",
    "test_iter = mx.io.NDArrayIter(data={'data': test_data}, label={'label': test_data}, batch_size = batch_size)\n",
    "#train_iter = mx.io.NDArrayIter(data={'data': train_data}, batch_size = batch_size)\n",
    "#test_iter = mx.io.NDArrayIter(data={'data': test_data}, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_latent = 2\n",
    "n_hidden_enc = 400\n",
    "n_hidden_dec = n_hidden_enc\n",
    "n_additional_layers = 1  \n",
    "act_type = 'relu'\n",
    "soft_zero = 1e-8\n",
    "model_prefix = 'vae_mxnet_{}d{}l{}h'.format(n_latent, n_additional_layers+1, n_hidden_enc)\n",
    "output_layer_name = 'output'\n",
    "# set to 0 to follow the architecture in the original paper\n",
    "\n",
    "def create_model(make_generator=False):\n",
    "\n",
    "    if not make_generator:\n",
    "        data = mx.sym.Variable('data')\n",
    "        label = mx.sym.Variable('label')\n",
    "        #data_flat = mx.sym.flatten(data)\n",
    "\n",
    "        # encoder\n",
    "        e1 = mx.sym.FullyConnected(data, num_hidden=n_hidden_enc)\n",
    "        e1act = mx.sym.Activation(e1, act_type=act_type)\n",
    "        for i in range(n_additional_layers):\n",
    "            e1 = mx.sym.FullyConnected(e1act, num_hidden=n_hidden_enc)\n",
    "            e1act = mx.sym.Activation(e1, act_type=act_type)\n",
    "        mu = mx.sym.FullyConnected(e1act, num_hidden=n_latent, name='enc_mu')\n",
    "        lv = mx.sym.FullyConnected(e1act, num_hidden=n_latent, name='enc_lv')\n",
    "        eps = mx.sym.random_normal(loc=0, scale=1, shape=(batch_size, n_latent))\n",
    "        z = mu + mx.sym.exp(0.5*lv)*eps\n",
    "        #mx.viz.plot_network(z)\n",
    "\n",
    "    if make_generator:  # build standalone decoder\n",
    "        Z = mx.sym.Variable('zsample')\n",
    "        g1 = mx.sym.FullyConnected(Z, num_hidden=n_hidden_dec, name='gfc0')\n",
    "    else:\n",
    "        g1 = mx.sym.FullyConnected(z, num_hidden=n_hidden_dec, name='gfc0')\n",
    "\n",
    "    g1act = mx.sym.Activation(g1, act_type=act_type, name='gfc0a')\n",
    "    for i in range(n_additional_layers):\n",
    "        g1 = mx.sym.FullyConnected(g1act, num_hidden=n_hidden_enc, name='gfc_add{}'.format(i))\n",
    "        g1act = mx.sym.Activation(g1, act_type=act_type, name='gfc_add{}a'.format(i))\n",
    "    y = mx.sym.FullyConnected(g1act, num_hidden=n_input, name='y')\n",
    "    yact = mx.sym.Activation(y, act_type=\"sigmoid\", name=output_layer_name)\n",
    "    #mx.viz.plot_network(y)\n",
    "    \n",
    "    if not make_generator:\n",
    "        KL = 0.5*mx.sym.sum(1+lv-mx.sym.pow(mu,2)-mx.sym.exp(lv),axis=1, name='KL')\n",
    "        logloss = mx.sym.sum(\n",
    "            label * mx.sym.log(yact+soft_zero)+ (1-label) * mx.symbol.log(1-yact+soft_zero), \n",
    "            axis=1, name='logloss')\n",
    "        loss = -logloss-KL\n",
    "        output = mx.symbol.MakeLoss(sum(loss),name='loss')\n",
    "    \n",
    "    if make_generator:\n",
    "        return yact\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mx.viz.plot_network(yact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mx.viz.plot_network(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=output,\n",
    "                    context=model_ctx,\n",
    "                    data_names=['data'],\n",
    "                    label_names=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "mod.init_params(initializer=mx.init.Xavier())\n",
    "mod.init_optimizer(optimizer='adam', optimizer_params=(('learning_rate', 0.001), ))\n",
    "metric = mx.metric.create('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 50\n",
    "#early_stopping = 5\n",
    "#todo implement early stopping\n",
    "start = time.time()\n",
    "\n",
    "print_period = n_epoch // 10\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "for epoch in tqdm_notebook(range(n_epoch), desc='epochs'):\n",
    "    train_iter.reset()\n",
    "    metric.reset()\n",
    "    #for batch in tqdm_notebook(train_iter, total=n_batches, desc='epoch{}'.format(epoch)):\n",
    "    for batch in train_iter:\n",
    "        mod.forward(batch, is_train=True)\n",
    "        mod.update_metric(metric, labels=batch.label)\n",
    "        mod.backward()\n",
    "        mod.update()\n",
    "    epoch_loss = metric.get()[1]\n",
    "    training_loss.append(epoch_loss)\n",
    "    \n",
    "    # metric.reset()  # metric should be reset within mod.score()\n",
    "    res = mod.score(test_iter, metric)\n",
    "    epoch_val_loss = res[0][1]\n",
    "    validation_loss.append(epoch_val_loss)\n",
    "    \n",
    "\n",
    "    #if early_stopping >0:\n",
    "    #    pass\n",
    "        \n",
    "    \n",
    "    if epoch % max(print_period,1) == 0:\n",
    "        tqdm.write('Epoch %d, Training loss %s, Validation loss %s' % (epoch, epoch_loss, epoch_val_loss))\n",
    "\n",
    "end = time.time()\n",
    "print('Time elapsed: {:.2f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.save_checkpoint(model_prefix, epoch)\n",
    "model_save_epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = np.linspace(1, n_epoch, len(training_loss))\n",
    "plt.plot(batch_x, -1*np.array(training_loss))\n",
    "plt.plot(batch_x, -1*np.array(validation_loss))\n",
    "plt.legend(['train', 'valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint(model_prefix, model_save_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing reconstruction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct=sym.get_internals()[output_layer_name + '_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_model = mx.mod.Module(symbol=reconstruct, context=model_ctx, data_names=['data'], label_names=None)\n",
    "reconstruct_model.bind(train_iter.provide_data)\n",
    "reconstruct_model.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter.reset()\n",
    "test_batch = test_iter.next()\n",
    "reconstruct_model.forward(test_batch, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reconstruct_model.get_outputs()[0].asnumpy()\n",
    "original = test_batch.data[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "idx = np.random.choice(batch_size, n_samples)\n",
    "_, axarr = plt.subplots(2, n_samples, figsize=(16,4))\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[0,i].imshow(original[j].reshape((28,28)), cmap='Greys')\n",
    "    if i==0:\n",
    "        axarr[0,i].set_title('original')\n",
    "    #axarr[0,i].axis('off')\n",
    "    axarr[0,i].get_xaxis().set_ticks([])\n",
    "    axarr[0,i].get_yaxis().set_ticks([])\n",
    "\n",
    "    axarr[1,i].imshow(result[j].reshape((28,28)), cmap='Greys')\n",
    "    if i==0:\n",
    "        axarr[1,i].set_title('reconstruction')\n",
    "    #axarr[1,i].axis('off')\n",
    "    axarr[1,i].get_xaxis().set_ticks([])\n",
    "    axarr[1,i].get_yaxis().set_ticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing latent space (when it is 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu = sym.get_internals()['enc_mu' + '_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_model = mx.mod.Module(symbol=z_mu, context=model_ctx, data_names=['data'], label_names=None)\n",
    "\n",
    "labeled_iter = mx.io.NDArrayIter(data={'data': test_data}, label={'label': mnist['test_label']}, \n",
    "                                 batch_size = 1000)\n",
    "latent_model.bind(labeled_iter.provide_data)\n",
    "latent_model.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = labeled_iter.next()\n",
    "latent_model.forward(batch_data, is_train=False)\n",
    "result = latent_model.get_outputs()[0].asnumpy()\n",
    "labels = batch_data.label[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.shape[1]==2:\n",
    "    from scipy.special import ndtri\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    fig, axarr = plt.subplots(1,2, figsize=(10,4))\n",
    "    im=axarr[0].scatter(result[:, 0], result[:, 1], c=labels, alpha=0.6, cmap='Paired')\n",
    "    axarr[0].set_title('scatter plot of $\\mu$')\n",
    "    axarr[0].axis('equal')\n",
    "    fig.colorbar(im, ax=axarr[0])\n",
    "\n",
    "    im=axarr[1].scatter(norm.cdf(result[:, 0]), norm.cdf(result[:, 1]), c=labels, alpha=0.6, cmap='Paired')\n",
    "    axarr[1].set_title('scatter plot of $\\mu$ on norm.cdf() transformed coordinates')\n",
    "    axarr[1].axis('equal')\n",
    "    fig.colorbar(im, ax=axarr[1])\n",
    "    plt.tight_layout()\n",
    "    if output_fig:\n",
    "        plt.savefig('2d_latent_space_for_test_samples.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample latent space and generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_model(make_generator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "zsamples = nd.array(np.random.randn(n_samples*n_samples, n_latent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_dict = arg_params\n",
    "arg_dict['zsample'] = zsamples\n",
    "e=generator.bind(ctx=data_ctx, args=arg_dict)\n",
    "result = e.forward()\n",
    "images = result[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.empty((28*n_samples, 28*n_samples))\n",
    "for i, img in enumerate(images):\n",
    "    x = i // n_samples\n",
    "    y = i % n_samples\n",
    "    canvas[(n_samples-y-1)*28:(n_samples-y)*28, x*28:(x+1)*28] = img.reshape(28, 28)\n",
    "plt.figure(figsize=(4, 4))        \n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"Greys\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "if output_fig:\n",
    "    plt.savefig('generated_samples_with_{}D_latent_space.png'.format(n_latent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid scan 2D latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_latent==2: \n",
    "    n_pts = 20\n",
    "\n",
    "    idx = np.arange(0, n_pts)\n",
    "\n",
    "    x = np.linspace(norm.cdf(-3), norm.cdf(3),n_pts)\n",
    "    x = ndtri(x)\n",
    "\n",
    "    x_grid = np.array(np.meshgrid(*[i for i in np.matlib.repmat(x,n_latent,1)]))\n",
    "    id_grid = np.array(np.meshgrid(*[i for i in np.matlib.repmat(idx,n_latent,1)]))\n",
    "\n",
    "    zsamples = nd.array(x_grid.reshape((n_latent, -1)).transpose())\n",
    "    zsamples_id = id_grid.reshape((n_latent, -1)).transpose()\n",
    "\n",
    "\n",
    "    # bind and execute\n",
    "    arg_dict = arg_params\n",
    "    arg_dict['zsample'] = zsamples\n",
    "    e=generator.bind(ctx=data_ctx, args=arg_dict)\n",
    "    result = e.forward()\n",
    "    images = result[0].asnumpy()\n",
    "\n",
    "    #plot\n",
    "    canvas = np.empty((28*n_pts, 28*n_pts))\n",
    "    for i, img in enumerate(images):\n",
    "        x, y = zsamples_id[i]\n",
    "        canvas[(n_pts-y-1)*28:(n_pts-y)*28, x*28:(x+1)*28] = img.reshape(28, 28)\n",
    "    plt.figure(figsize=(6, 6))        \n",
    "    plt.imshow(canvas, origin=\"upper\", cmap=\"Greys\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if output_fig:\n",
    "        plt.savefig('2d_latent_space_scan_for_generation.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {
    "013831ad95a14b50989742a490b65ad0": {
     "views": []
    },
    "060dbcfa0dbf4ec79c19a6082dfcde16": {
     "views": []
    },
    "064f5c79b47748cc85671b2dfe3a7b11": {
     "views": []
    },
    "075482b08bf8473d84a539c6ed4a2cd5": {
     "views": []
    },
    "0d438ff52cc74867852a17039f872b30": {
     "views": []
    },
    "0de6820e97e64c0e9ba1713cb31270c5": {
     "views": []
    },
    "11ceed56010c4035a8e00f0e777a32ef": {
     "views": []
    },
    "128439858fca48bf896e3bc048e434c6": {
     "views": []
    },
    "17badb0485644615ace649fbf7221b2b": {
     "views": []
    },
    "252bad49b82041cf937f3957f2738138": {
     "views": []
    },
    "2757715fdbed476fae6764d36440abf4": {
     "views": []
    },
    "28b36582d56742e991cbb4eeaaaa6815": {
     "views": []
    },
    "2c15dc27263a4aeba4ad716d26a6eb51": {
     "views": []
    },
    "2c3383be9c2b42139fa75dcaa0f76362": {
     "views": []
    },
    "2d2404d2cbea46eca2df100d4a216ab0": {
     "views": []
    },
    "312a7d065faf42efa6d590abd99af6e4": {
     "views": []
    },
    "3609be49f4754b619ee5f9b8dd5655c2": {
     "views": []
    },
    "367462141a584d36b8c116e322840ec2": {
     "views": []
    },
    "3bcccfd7f2a048d1ba7277cbfef35070": {
     "views": []
    },
    "3cc84227a2994ae68724d39f91fe4888": {
     "views": []
    },
    "3d2398ca4f0444a28f20c5526cc17f60": {
     "views": []
    },
    "42d4a8624c5d43cdafe4d95b6093088d": {
     "views": []
    },
    "430e7722f893454fb6fb6d7067038a52": {
     "views": []
    },
    "45bce29afb8e45f989b2a7ce35bafc06": {
     "views": []
    },
    "4d3698d1eb7445f39af9a8551e125574": {
     "views": []
    },
    "59278d56d73b42a3b54cc5486ec9d28a": {
     "views": []
    },
    "5a88eafb8bd041df90e5b03b9dbd2930": {
     "views": []
    },
    "5cac8f55cbd447bd8e04714c0be9cfdd": {
     "views": []
    },
    "613f4b7c012547f8809bebac99130b1f": {
     "views": []
    },
    "66fe705008014e34bd1b66a97ca00a52": {
     "views": []
    },
    "693e5755d56d453ea1b30f08bd3cb264": {
     "views": []
    },
    "6ccbd5c95fbb4cd3b610be1af7b0cb28": {
     "views": []
    },
    "70bd4dc3920145df96c0ada89dd26eb7": {
     "views": []
    },
    "744afe6e043f41b4ae79c8638e8e983f": {
     "views": []
    },
    "7843ec29c508499bb945789fdb7b482c": {
     "views": []
    },
    "78d7e99ed96e463f897c738a52f30baf": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "7d524cdb5a314099b9c5a4152c6b129e": {
     "views": []
    },
    "7d5f644a33f6467bba4d1b5bd1962c0f": {
     "views": []
    },
    "7e879703f4574bac9de4137d1155c8ce": {
     "views": []
    },
    "7e8d33c949fb426e81125f082b7deb7c": {
     "views": []
    },
    "81125a7384804e539de58b79c381d7fa": {
     "views": []
    },
    "81633120e61a47c49e7e7cde277d7af9": {
     "views": []
    },
    "84734c2e88a0466e9492e93747befc49": {
     "views": []
    },
    "86ed6062cea3471eb52e395764c1edb4": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "94ad29c1c4644f45a4749874ddd0c1fc": {
     "views": []
    },
    "953eb61e1af74f32998d6f61967006cb": {
     "views": []
    },
    "98b9cda7c3ff48df8639759fd249bee8": {
     "views": []
    },
    "9912b3cefd69439cae64925eedf97ee3": {
     "views": []
    },
    "9989ee405297420da7ba25fc0a2068cc": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "9a0de86e07334d27a052b2f4edd67ed1": {
     "views": []
    },
    "9c74970b79904db087057befbe464d16": {
     "views": []
    },
    "9d82a3bd77894311b87a19b044086018": {
     "views": []
    },
    "9d9ce67edd2f46c6969644ce18c40464": {
     "views": []
    },
    "9eb346c6adf34137a0e4e2cc5b3a9df0": {
     "views": []
    },
    "9ec367a05b8f41d69afc7923c11b632c": {
     "views": []
    },
    "9fa6d568f8a549d8811cccd8649f9ce2": {
     "views": []
    },
    "a19d63a0324e4cc2bb3af7dc331b5abc": {
     "views": []
    },
    "a3636a2cce744c75bb7d1bd672aaa1a9": {
     "views": []
    },
    "a3e4aa4b2ec94dfba8e07f2641229ed1": {
     "views": []
    },
    "a64837790ef04869a6b399251dcea040": {
     "views": []
    },
    "aa41497993db4f1e8ce8cb8e31751d52": {
     "views": []
    },
    "aab984197cee4e52b8d062bd8cfa9878": {
     "views": []
    },
    "ab33b20130ba4158b90b2c93cdb2116c": {
     "views": []
    },
    "ab3f83b6a6b84087b565c34a2a76aa36": {
     "views": []
    },
    "ab91869bd6e347b0adbcb3fb3a82db14": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "b5537aa47c3d4088beb0e83b6cc35b2c": {
     "views": []
    },
    "b810da789f3442a5a93b30914e2b6cb0": {
     "views": []
    },
    "ba284efbb6444b74808d8ad20d4ab2d8": {
     "views": []
    },
    "bca4373a0d0e4741b9391e51dfe05525": {
     "views": []
    },
    "be8f818802844d00b6dec3892a93fe01": {
     "views": []
    },
    "beffdcc6f9514a30a71ec609c0133955": {
     "views": []
    },
    "bf6b616cbbc949dd874c3e0e4e49fe83": {
     "views": []
    },
    "c18c5aed11b647a6b0d4efcbd6b895e7": {
     "views": []
    },
    "c1da8befa7c9434099a6bd883e6039f7": {
     "views": []
    },
    "c5d5c7c363d5436688ed3780ccb5f437": {
     "views": []
    },
    "c623d679576c4d2199122117673c7d2d": {
     "views": []
    },
    "c6b3e5ff5206400d92b012428dc13ada": {
     "views": []
    },
    "cac058af8fe84d9090488f97eaf6e2c6": {
     "views": []
    },
    "cb4662815adb4cfd92fc21c09c62b242": {
     "views": []
    },
    "cfd34e25998f440193b51db9aa1aee1a": {
     "views": []
    },
    "d25ba13396474cfbba1355b34324f2c8": {
     "views": []
    },
    "d39bdd8023c746b4a823012e59c3e695": {
     "views": []
    },
    "d5239161f55643aa96a7f368202b65ff": {
     "views": []
    },
    "d6c0abd6d4c4438eb7a1341001800aa6": {
     "views": []
    },
    "d9e16f99be3f4a16a2a2d4afb41052a5": {
     "views": []
    },
    "da7ed38c90e7444fbd8cb05ba7aa29ba": {
     "views": []
    },
    "db876aad73d44ec684ff8617bb216bb6": {
     "views": []
    },
    "dc30ca57c7484d6aa2fe395006333eee": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "e0ee3a3f1333466980d7d56ebee03560": {
     "views": []
    },
    "e53d57d91ae346188283343ae5aa75d7": {
     "views": []
    },
    "ebe196e6565e4193b39f079243a8b71e": {
     "views": []
    },
    "ec3003f4855e4b0796c6929aa07c9bdf": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "ed07ff00310e42f190452577f1144af3": {
     "views": []
    },
    "f4218c2fd6a7434181f548e28ffbdee6": {
     "views": []
    },
    "f4b6303e7c6c41bb8cb3a0f0e87dfbef": {
     "views": []
    },
    "f6e60e625417416fa45c478d419e820b": {
     "views": []
    },
    "f747d9c58a844bf5b5939e5f6b7f3f77": {
     "views": []
    },
    "f97975725348441ebd204396e52b14ec": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "fc4f654f915a4bd49cdbb664ee2b74cf": {
     "views": []
    },
    "fca1f6e81f9942b78671ffced0a6901e": {
     "views": []
    },
    "feb02650db954c01aefdc7024eac9510": {
     "views": []
    },
    "ff9730625878484bbbad310801d7b64d": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
